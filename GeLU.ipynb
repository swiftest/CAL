{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7477a63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69efde76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaky_relu(z, alpha=0.1):\n",
    "    return np.maximum(alpha*z, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb26fb26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "font_style = dict(family='DejaVu Sans', weight='black', size=14)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 8))\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "ax = plt.gca()  # get current axis 获得坐标轴对象\n",
    "\n",
    "# 将右边、上边这两条边颜色设置为空 其实就相当于抹掉这两条边\n",
    "ax.spines['right'].set_color('none')\n",
    "ax.spines['top'].set_color('none')\n",
    "\n",
    "# 指定下边作为x轴，指定左边作为y轴\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "\n",
    "# 指定data设置的bottom(也就是指定的x轴)绑定到y轴的0这个点上\n",
    "ax.spines['bottom'].set_position(('data', 0))\n",
    "ax.spines['left'].set_position(('data', 0))\n",
    "\n",
    "x = torch.linspace(-5, 5, 5000)\n",
    "y1 = 0.5 * x * (1 + torch.tanh(math.sqrt(2/math.pi) * (x + 0.044715 * x**3)))\n",
    "y2 = (math.e**x - math.e**(-x)) / (math.e**x + math.e**(-x))\n",
    "y3 = torch.max(torch.Tensor([0]), x)\n",
    "# 函数图像\n",
    "plt.plot(x.numpy(), y3.numpy(), 'r-', linewidth=2, label='ReLU')\n",
    "plt.plot(x.numpy(), leaky_relu(x, 0.1), linewidth=2, label='Leaky ReLU')\n",
    "plt.plot(x.numpy(), y1.numpy(), linewidth=2, label='GELU')\n",
    "plt.plot(x.numpy(), y2.numpy(), 'b-', linewidth=2, label='Tanh')\n",
    "plt.legend(fontsize=15)\n",
    "plt.show()\n",
    "fig.savefig('./activation.pdf', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d95f75c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class GELU in module torch.nn.modules.activation:\n",
      "\n",
      "class GELU(torch.nn.modules.module.Module)\n",
      " |  GELU() -> None\n",
      " |  \n",
      " |  Applies the Gaussian Error Linear Units function:\n",
      " |  \n",
      " |  .. math:: \\text{GELU}(x) = x * \\Phi(x)\n",
      " |  \n",
      " |  where :math:`\\Phi(x)` is the Cumulative Distribution Function for Gaussian Distribution.\n",
      " |  \n",
      " |  Shape:\n",
      " |      - Input: :math:`(*)`, where :math:`*` means any number of dimensions.\n",
      " |      - Output: :math:`(*)`, same shape as the input.\n",
      " |  \n",
      " |  .. image:: ../scripts/activation_images/GELU.png\n",
      " |  \n",
      " |  Examples::\n",
      " |  \n",
      " |      >>> m = nn.GELU()\n",
      " |      >>> input = torch.randn(2)\n",
      " |      >>> output = m(input)\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      GELU\n",
      " |      torch.nn.modules.module.Module\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  forward(self, input: torch.Tensor) -> torch.Tensor\n",
      " |      Defines the computation performed at every call.\n",
      " |      \n",
      " |      Should be overridden by all subclasses.\n",
      " |      \n",
      " |      .. note::\n",
      " |          Although the recipe for forward pass needs to be defined within\n",
      " |          this function, one should call the :class:`Module` instance afterwards\n",
      " |          instead of this since the former takes care of running the\n",
      " |          registered hooks while the latter silently ignores them.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  __call__ = _call_impl(self, *input, **kwargs)\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __dir__(self)\n",
      " |      Default dir() implementation.\n",
      " |  \n",
      " |  __getattr__(self, name: str) -> Union[torch.Tensor, ForwardRef('Module')]\n",
      " |  \n",
      " |  __init__(self) -> None\n",
      " |      Initializes internal Module state, shared by both nn.Module and ScriptModule.\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setattr__(self, name: str, value: Union[torch.Tensor, ForwardRef('Module')]) -> None\n",
      " |      Implement setattr(self, name, value).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  add_module(self, name: str, module: Optional[ForwardRef('Module')]) -> None\n",
      " |      Adds a child module to the current module.\n",
      " |      \n",
      " |      The module can be accessed as an attribute using the given name.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (string): name of the child module. The child module can be\n",
      " |              accessed from this module using the given name\n",
      " |          module (Module): child module to be added to the module.\n",
      " |  \n",
      " |  apply(self: ~T, fn: Callable[[ForwardRef('Module')], NoneType]) -> ~T\n",
      " |      Applies ``fn`` recursively to every submodule (as returned by ``.children()``)\n",
      " |      as well as self. Typical use includes initializing the parameters of a model\n",
      " |      (see also :ref:`nn-init-doc`).\n",
      " |      \n",
      " |      Args:\n",
      " |          fn (:class:`Module` -> None): function to be applied to each submodule\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> @torch.no_grad()\n",
      " |          >>> def init_weights(m):\n",
      " |          >>>     print(m)\n",
      " |          >>>     if type(m) == nn.Linear:\n",
      " |          >>>         m.weight.fill_(1.0)\n",
      " |          >>>         print(m.weight)\n",
      " |          >>> net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2))\n",
      " |          >>> net.apply(init_weights)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 1.,  1.],\n",
      " |                  [ 1.,  1.]])\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 1.,  1.],\n",
      " |                  [ 1.,  1.]])\n",
      " |          Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          )\n",
      " |          Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          )\n",
      " |  \n",
      " |  bfloat16(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to ``bfloat16`` datatype.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  buffers(self, recurse: bool = True) -> Iterator[torch.Tensor]\n",
      " |      Returns an iterator over module buffers.\n",
      " |      \n",
      " |      Args:\n",
      " |          recurse (bool): if True, then yields buffers of this module\n",
      " |              and all submodules. Otherwise, yields only buffers that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          torch.Tensor: module buffer\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for buf in model.buffers():\n",
      " |          >>>     print(type(buf), buf.size())\n",
      " |          <class 'torch.Tensor'> (20L,)\n",
      " |          <class 'torch.Tensor'> (20L, 1L, 5L, 5L)\n",
      " |  \n",
      " |  children(self) -> Iterator[ForwardRef('Module')]\n",
      " |      Returns an iterator over immediate children modules.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Module: a child module\n",
      " |  \n",
      " |  cpu(self: ~T) -> ~T\n",
      " |      Moves all model parameters and buffers to the CPU.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  cuda(self: ~T, device: Union[int, torch.device, NoneType] = None) -> ~T\n",
      " |      Moves all model parameters and buffers to the GPU.\n",
      " |      \n",
      " |      This also makes associated parameters and buffers different objects. So\n",
      " |      it should be called before constructing optimizer if the module will\n",
      " |      live on GPU while being optimized.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Args:\n",
      " |          device (int, optional): if specified, all parameters will be\n",
      " |              copied to that device\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  double(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to ``double`` datatype.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  eval(self: ~T) -> ~T\n",
      " |      Sets the module in evaluation mode.\n",
      " |      \n",
      " |      This has any effect only on certain modules. See documentations of\n",
      " |      particular modules for details of their behaviors in training/evaluation\n",
      " |      mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n",
      " |      etc.\n",
      " |      \n",
      " |      This is equivalent with :meth:`self.train(False) <torch.nn.Module.train>`.\n",
      " |      \n",
      " |      See :ref:`locally-disable-grad-doc` for a comparison between\n",
      " |      `.eval()` and several similar mechanisms that may be confused with it.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  extra_repr(self) -> str\n",
      " |      Set the extra representation of the module\n",
      " |      \n",
      " |      To print customized extra information, you should re-implement\n",
      " |      this method in your own modules. Both single-line and multi-line\n",
      " |      strings are acceptable.\n",
      " |  \n",
      " |  float(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to ``float`` datatype.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  get_buffer(self, target: str) -> 'Tensor'\n",
      " |      Returns the buffer given by ``target`` if it exists,\n",
      " |      otherwise throws an error.\n",
      " |      \n",
      " |      See the docstring for ``get_submodule`` for a more detailed\n",
      " |      explanation of this method's functionality as well as how to\n",
      " |      correctly specify ``target``.\n",
      " |      \n",
      " |      Args:\n",
      " |          target: The fully-qualified string name of the buffer\n",
      " |              to look for. (See ``get_submodule`` for how to specify a\n",
      " |              fully-qualified string.)\n",
      " |      \n",
      " |      Returns:\n",
      " |          torch.Tensor: The buffer referenced by ``target``\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: If the target string references an invalid\n",
      " |              path or resolves to something that is not a\n",
      " |              buffer\n",
      " |  \n",
      " |  get_extra_state(self) -> Any\n",
      " |      Returns any extra state to include in the module's state_dict.\n",
      " |      Implement this and a corresponding :func:`set_extra_state` for your module\n",
      " |      if you need to store extra state. This function is called when building the\n",
      " |      module's `state_dict()`.\n",
      " |      \n",
      " |      Note that extra state should be pickleable to ensure working serialization\n",
      " |      of the state_dict. We only provide provide backwards compatibility guarantees\n",
      " |      for serializing Tensors; other objects may break backwards compatibility if\n",
      " |      their serialized pickled form changes.\n",
      " |      \n",
      " |      Returns:\n",
      " |          object: Any extra state to store in the module's state_dict\n",
      " |  \n",
      " |  get_parameter(self, target: str) -> 'Parameter'\n",
      " |      Returns the parameter given by ``target`` if it exists,\n",
      " |      otherwise throws an error.\n",
      " |      \n",
      " |      See the docstring for ``get_submodule`` for a more detailed\n",
      " |      explanation of this method's functionality as well as how to\n",
      " |      correctly specify ``target``.\n",
      " |      \n",
      " |      Args:\n",
      " |          target: The fully-qualified string name of the Parameter\n",
      " |              to look for. (See ``get_submodule`` for how to specify a\n",
      " |              fully-qualified string.)\n",
      " |      \n",
      " |      Returns:\n",
      " |          torch.nn.Parameter: The Parameter referenced by ``target``\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: If the target string references an invalid\n",
      " |              path or resolves to something that is not an\n",
      " |              ``nn.Parameter``\n",
      " |  \n",
      " |  get_submodule(self, target: str) -> 'Module'\n",
      " |      Returns the submodule given by ``target`` if it exists,\n",
      " |      otherwise throws an error.\n",
      " |      \n",
      " |      For example, let's say you have an ``nn.Module`` ``A`` that\n",
      " |      looks like this:\n",
      " |      \n",
      " |      .. code-block::text\n",
      " |      \n",
      " |          A(\n",
      " |              (net_b): Module(\n",
      " |                  (net_c): Module(\n",
      " |                      (conv): Conv2d(16, 33, kernel_size=(3, 3), stride=(2, 2))\n",
      " |                  )\n",
      " |                  (linear): Linear(in_features=100, out_features=200, bias=True)\n",
      " |              )\n",
      " |          )\n",
      " |      \n",
      " |      (The diagram shows an ``nn.Module`` ``A``. ``A`` has a nested\n",
      " |      submodule ``net_b``, which itself has two submodules ``net_c``\n",
      " |      and ``linear``. ``net_c`` then has a submodule ``conv``.)\n",
      " |      \n",
      " |      To check whether or not we have the ``linear`` submodule, we\n",
      " |      would call ``get_submodule(\"net_b.linear\")``. To check whether\n",
      " |      we have the ``conv`` submodule, we would call\n",
      " |      ``get_submodule(\"net_b.net_c.conv\")``.\n",
      " |      \n",
      " |      The runtime of ``get_submodule`` is bounded by the degree\n",
      " |      of module nesting in ``target``. A query against\n",
      " |      ``named_modules`` achieves the same result, but it is O(N) in\n",
      " |      the number of transitive modules. So, for a simple check to see\n",
      " |      if some submodule exists, ``get_submodule`` should always be\n",
      " |      used.\n",
      " |      \n",
      " |      Args:\n",
      " |          target: The fully-qualified string name of the submodule\n",
      " |              to look for. (See above example for how to specify a\n",
      " |              fully-qualified string.)\n",
      " |      \n",
      " |      Returns:\n",
      " |          torch.nn.Module: The submodule referenced by ``target``\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: If the target string references an invalid\n",
      " |              path or resolves to something that is not an\n",
      " |              ``nn.Module``\n",
      " |  \n",
      " |  half(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to ``half`` datatype.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  load_state_dict(self, state_dict: 'OrderedDict[str, Tensor]', strict: bool = True)\n",
      " |      Copies parameters and buffers from :attr:`state_dict` into\n",
      " |      this module and its descendants. If :attr:`strict` is ``True``, then\n",
      " |      the keys of :attr:`state_dict` must exactly match the keys returned\n",
      " |      by this module's :meth:`~torch.nn.Module.state_dict` function.\n",
      " |      \n",
      " |      Args:\n",
      " |          state_dict (dict): a dict containing parameters and\n",
      " |              persistent buffers.\n",
      " |          strict (bool, optional): whether to strictly enforce that the keys\n",
      " |              in :attr:`state_dict` match the keys returned by this module's\n",
      " |              :meth:`~torch.nn.Module.state_dict` function. Default: ``True``\n",
      " |      \n",
      " |      Returns:\n",
      " |          ``NamedTuple`` with ``missing_keys`` and ``unexpected_keys`` fields:\n",
      " |              * **missing_keys** is a list of str containing the missing keys\n",
      " |              * **unexpected_keys** is a list of str containing the unexpected keys\n",
      " |      \n",
      " |      Note:\n",
      " |          If a parameter or buffer is registered as ``None`` and its corresponding key\n",
      " |          exists in :attr:`state_dict`, :meth:`load_state_dict` will raise a\n",
      " |          ``RuntimeError``.\n",
      " |  \n",
      " |  modules(self) -> Iterator[ForwardRef('Module')]\n",
      " |      Returns an iterator over all modules in the network.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Module: a module in the network\n",
      " |      \n",
      " |      Note:\n",
      " |          Duplicate modules are returned only once. In the following\n",
      " |          example, ``l`` will be returned only once.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> l = nn.Linear(2, 2)\n",
      " |          >>> net = nn.Sequential(l, l)\n",
      " |          >>> for idx, m in enumerate(net.modules()):\n",
      " |                  print(idx, '->', m)\n",
      " |      \n",
      " |          0 -> Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          )\n",
      " |          1 -> Linear(in_features=2, out_features=2, bias=True)\n",
      " |  \n",
      " |  named_buffers(self, prefix: str = '', recurse: bool = True) -> Iterator[Tuple[str, torch.Tensor]]\n",
      " |      Returns an iterator over module buffers, yielding both the\n",
      " |      name of the buffer as well as the buffer itself.\n",
      " |      \n",
      " |      Args:\n",
      " |          prefix (str): prefix to prepend to all buffer names.\n",
      " |          recurse (bool): if True, then yields buffers of this module\n",
      " |              and all submodules. Otherwise, yields only buffers that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, torch.Tensor): Tuple containing the name and buffer\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for name, buf in self.named_buffers():\n",
      " |          >>>    if name in ['running_var']:\n",
      " |          >>>        print(buf.size())\n",
      " |  \n",
      " |  named_children(self) -> Iterator[Tuple[str, ForwardRef('Module')]]\n",
      " |      Returns an iterator over immediate children modules, yielding both\n",
      " |      the name of the module as well as the module itself.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, Module): Tuple containing a name and child module\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for name, module in model.named_children():\n",
      " |          >>>     if name in ['conv4', 'conv5']:\n",
      " |          >>>         print(module)\n",
      " |  \n",
      " |  named_modules(self, memo: Optional[Set[ForwardRef('Module')]] = None, prefix: str = '', remove_duplicate: bool = True)\n",
      " |      Returns an iterator over all modules in the network, yielding\n",
      " |      both the name of the module as well as the module itself.\n",
      " |      \n",
      " |      Args:\n",
      " |          memo: a memo to store the set of modules already added to the result\n",
      " |          prefix: a prefix that will be added to the name of the module\n",
      " |          remove_duplicate: whether to remove the duplicated module instances in the result\n",
      " |              or not\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, Module): Tuple of name and module\n",
      " |      \n",
      " |      Note:\n",
      " |          Duplicate modules are returned only once. In the following\n",
      " |          example, ``l`` will be returned only once.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> l = nn.Linear(2, 2)\n",
      " |          >>> net = nn.Sequential(l, l)\n",
      " |          >>> for idx, m in enumerate(net.named_modules()):\n",
      " |                  print(idx, '->', m)\n",
      " |      \n",
      " |          0 -> ('', Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          ))\n",
      " |          1 -> ('0', Linear(in_features=2, out_features=2, bias=True))\n",
      " |  \n",
      " |  named_parameters(self, prefix: str = '', recurse: bool = True) -> Iterator[Tuple[str, torch.nn.parameter.Parameter]]\n",
      " |      Returns an iterator over module parameters, yielding both the\n",
      " |      name of the parameter as well as the parameter itself.\n",
      " |      \n",
      " |      Args:\n",
      " |          prefix (str): prefix to prepend to all parameter names.\n",
      " |          recurse (bool): if True, then yields parameters of this module\n",
      " |              and all submodules. Otherwise, yields only parameters that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, Parameter): Tuple containing the name and parameter\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for name, param in self.named_parameters():\n",
      " |          >>>    if name in ['bias']:\n",
      " |          >>>        print(param.size())\n",
      " |  \n",
      " |  parameters(self, recurse: bool = True) -> Iterator[torch.nn.parameter.Parameter]\n",
      " |      Returns an iterator over module parameters.\n",
      " |      \n",
      " |      This is typically passed to an optimizer.\n",
      " |      \n",
      " |      Args:\n",
      " |          recurse (bool): if True, then yields parameters of this module\n",
      " |              and all submodules. Otherwise, yields only parameters that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Parameter: module parameter\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for param in model.parameters():\n",
      " |          >>>     print(type(param), param.size())\n",
      " |          <class 'torch.Tensor'> (20L,)\n",
      " |          <class 'torch.Tensor'> (20L, 1L, 5L, 5L)\n",
      " |  \n",
      " |  register_backward_hook(self, hook: Callable[[ForwardRef('Module'), Union[Tuple[torch.Tensor, ...], torch.Tensor], Union[Tuple[torch.Tensor, ...], torch.Tensor]], Optional[torch.Tensor]]) -> torch.utils.hooks.RemovableHandle\n",
      " |      Registers a backward hook on the module.\n",
      " |      \n",
      " |      This function is deprecated in favor of :meth:`~torch.nn.Module.register_full_backward_hook` and\n",
      " |      the behavior of this function will change in future versions.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_buffer(self, name: str, tensor: Optional[torch.Tensor], persistent: bool = True) -> None\n",
      " |      Adds a buffer to the module.\n",
      " |      \n",
      " |      This is typically used to register a buffer that should not to be\n",
      " |      considered a model parameter. For example, BatchNorm's ``running_mean``\n",
      " |      is not a parameter, but is part of the module's state. Buffers, by\n",
      " |      default, are persistent and will be saved alongside parameters. This\n",
      " |      behavior can be changed by setting :attr:`persistent` to ``False``. The\n",
      " |      only difference between a persistent buffer and a non-persistent buffer\n",
      " |      is that the latter will not be a part of this module's\n",
      " |      :attr:`state_dict`.\n",
      " |      \n",
      " |      Buffers can be accessed as attributes using given names.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (string): name of the buffer. The buffer can be accessed\n",
      " |              from this module using the given name\n",
      " |          tensor (Tensor or None): buffer to be registered. If ``None``, then operations\n",
      " |              that run on buffers, such as :attr:`cuda`, are ignored. If ``None``,\n",
      " |              the buffer is **not** included in the module's :attr:`state_dict`.\n",
      " |          persistent (bool): whether the buffer is part of this module's\n",
      " |              :attr:`state_dict`.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> self.register_buffer('running_mean', torch.zeros(num_features))\n",
      " |  \n",
      " |  register_forward_hook(self, hook: Callable[..., NoneType]) -> torch.utils.hooks.RemovableHandle\n",
      " |      Registers a forward hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time after :func:`forward` has computed an output.\n",
      " |      It should have the following signature::\n",
      " |      \n",
      " |          hook(module, input, output) -> None or modified output\n",
      " |      \n",
      " |      The input contains only the positional arguments given to the module.\n",
      " |      Keyword arguments won't be passed to the hooks and only to the ``forward``.\n",
      " |      The hook can modify the output. It can modify the input inplace but\n",
      " |      it will not have effect on forward since this is called after\n",
      " |      :func:`forward` is called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_forward_pre_hook(self, hook: Callable[..., NoneType]) -> torch.utils.hooks.RemovableHandle\n",
      " |      Registers a forward pre-hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time before :func:`forward` is invoked.\n",
      " |      It should have the following signature::\n",
      " |      \n",
      " |          hook(module, input) -> None or modified input\n",
      " |      \n",
      " |      The input contains only the positional arguments given to the module.\n",
      " |      Keyword arguments won't be passed to the hooks and only to the ``forward``.\n",
      " |      The hook can modify the input. User can either return a tuple or a\n",
      " |      single modified value in the hook. We will wrap the value into a tuple\n",
      " |      if a single value is returned(unless that value is already a tuple).\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_full_backward_hook(self, hook: Callable[[ForwardRef('Module'), Union[Tuple[torch.Tensor, ...], torch.Tensor], Union[Tuple[torch.Tensor, ...], torch.Tensor]], Optional[torch.Tensor]]) -> torch.utils.hooks.RemovableHandle\n",
      " |      Registers a backward hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time the gradients with respect to module\n",
      " |      inputs are computed. The hook should have the following signature::\n",
      " |      \n",
      " |          hook(module, grad_input, grad_output) -> tuple(Tensor) or None\n",
      " |      \n",
      " |      The :attr:`grad_input` and :attr:`grad_output` are tuples that contain the gradients\n",
      " |      with respect to the inputs and outputs respectively. The hook should\n",
      " |      not modify its arguments, but it can optionally return a new gradient with\n",
      " |      respect to the input that will be used in place of :attr:`grad_input` in\n",
      " |      subsequent computations. :attr:`grad_input` will only correspond to the inputs given\n",
      " |      as positional arguments and all kwarg arguments are ignored. Entries\n",
      " |      in :attr:`grad_input` and :attr:`grad_output` will be ``None`` for all non-Tensor\n",
      " |      arguments.\n",
      " |      \n",
      " |      For technical reasons, when this hook is applied to a Module, its forward function will\n",
      " |      receive a view of each Tensor passed to the Module. Similarly the caller will receive a view\n",
      " |      of each Tensor returned by the Module's forward function.\n",
      " |      \n",
      " |      .. warning ::\n",
      " |          Modifying inputs or outputs inplace is not allowed when using backward hooks and\n",
      " |          will raise an error.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_module(self, name: str, module: Optional[ForwardRef('Module')]) -> None\n",
      " |      Alias for :func:`add_module`.\n",
      " |  \n",
      " |  register_parameter(self, name: str, param: Optional[torch.nn.parameter.Parameter]) -> None\n",
      " |      Adds a parameter to the module.\n",
      " |      \n",
      " |      The parameter can be accessed as an attribute using given name.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (string): name of the parameter. The parameter can be accessed\n",
      " |              from this module using the given name\n",
      " |          param (Parameter or None): parameter to be added to the module. If\n",
      " |              ``None``, then operations that run on parameters, such as :attr:`cuda`,\n",
      " |              are ignored. If ``None``, the parameter is **not** included in the\n",
      " |              module's :attr:`state_dict`.\n",
      " |  \n",
      " |  requires_grad_(self: ~T, requires_grad: bool = True) -> ~T\n",
      " |      Change if autograd should record operations on parameters in this\n",
      " |      module.\n",
      " |      \n",
      " |      This method sets the parameters' :attr:`requires_grad` attributes\n",
      " |      in-place.\n",
      " |      \n",
      " |      This method is helpful for freezing part of the module for finetuning\n",
      " |      or training parts of a model individually (e.g., GAN training).\n",
      " |      \n",
      " |      See :ref:`locally-disable-grad-doc` for a comparison between\n",
      " |      `.requires_grad_()` and several similar mechanisms that may be confused with it.\n",
      " |      \n",
      " |      Args:\n",
      " |          requires_grad (bool): whether autograd should record operations on\n",
      " |                                parameters in this module. Default: ``True``.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  set_extra_state(self, state: Any)\n",
      " |      This function is called from :func:`load_state_dict` to handle any extra state\n",
      " |      found within the `state_dict`. Implement this function and a corresponding\n",
      " |      :func:`get_extra_state` for your module if you need to store extra state within its\n",
      " |      `state_dict`.\n",
      " |      \n",
      " |      Args:\n",
      " |          state (dict): Extra state from the `state_dict`\n",
      " |  \n",
      " |  share_memory(self: ~T) -> ~T\n",
      " |      See :meth:`torch.Tensor.share_memory_`\n",
      " |  \n",
      " |  state_dict(self, destination=None, prefix='', keep_vars=False)\n",
      " |      Returns a dictionary containing a whole state of the module.\n",
      " |      \n",
      " |      Both parameters and persistent buffers (e.g. running averages) are\n",
      " |      included. Keys are corresponding parameter and buffer names.\n",
      " |      Parameters and buffers set to ``None`` are not included.\n",
      " |      \n",
      " |      Returns:\n",
      " |          dict:\n",
      " |              a dictionary containing a whole state of the module\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> module.state_dict().keys()\n",
      " |          ['bias', 'weight']\n",
      " |  \n",
      " |  to(self, *args, **kwargs)\n",
      " |      Moves and/or casts the parameters and buffers.\n",
      " |      \n",
      " |      This can be called as\n",
      " |      \n",
      " |      .. function:: to(device=None, dtype=None, non_blocking=False)\n",
      " |         :noindex:\n",
      " |      \n",
      " |      .. function:: to(dtype, non_blocking=False)\n",
      " |         :noindex:\n",
      " |      \n",
      " |      .. function:: to(tensor, non_blocking=False)\n",
      " |         :noindex:\n",
      " |      \n",
      " |      .. function:: to(memory_format=torch.channels_last)\n",
      " |         :noindex:\n",
      " |      \n",
      " |      Its signature is similar to :meth:`torch.Tensor.to`, but only accepts\n",
      " |      floating point or complex :attr:`dtype`\\ s. In addition, this method will\n",
      " |      only cast the floating point or complex parameters and buffers to :attr:`dtype`\n",
      " |      (if given). The integral parameters and buffers will be moved\n",
      " |      :attr:`device`, if that is given, but with dtypes unchanged. When\n",
      " |      :attr:`non_blocking` is set, it tries to convert/move asynchronously\n",
      " |      with respect to the host if possible, e.g., moving CPU Tensors with\n",
      " |      pinned memory to CUDA devices.\n",
      " |      \n",
      " |      See below for examples.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Args:\n",
      " |          device (:class:`torch.device`): the desired device of the parameters\n",
      " |              and buffers in this module\n",
      " |          dtype (:class:`torch.dtype`): the desired floating point or complex dtype of\n",
      " |              the parameters and buffers in this module\n",
      " |          tensor (torch.Tensor): Tensor whose dtype and device are the desired\n",
      " |              dtype and device for all parameters and buffers in this module\n",
      " |          memory_format (:class:`torch.memory_format`): the desired memory\n",
      " |              format for 4D parameters and buffers in this module (keyword\n",
      " |              only argument)\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |      \n",
      " |      Examples::\n",
      " |      \n",
      " |          >>> linear = nn.Linear(2, 2)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1913, -0.3420],\n",
      " |                  [-0.5113, -0.2325]])\n",
      " |          >>> linear.to(torch.double)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1913, -0.3420],\n",
      " |                  [-0.5113, -0.2325]], dtype=torch.float64)\n",
      " |          >>> gpu1 = torch.device(\"cuda:1\")\n",
      " |          >>> linear.to(gpu1, dtype=torch.half, non_blocking=True)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1914, -0.3420],\n",
      " |                  [-0.5112, -0.2324]], dtype=torch.float16, device='cuda:1')\n",
      " |          >>> cpu = torch.device(\"cpu\")\n",
      " |          >>> linear.to(cpu)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1914, -0.3420],\n",
      " |                  [-0.5112, -0.2324]], dtype=torch.float16)\n",
      " |      \n",
      " |          >>> linear = nn.Linear(2, 2, bias=None).to(torch.cdouble)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.3741+0.j,  0.2382+0.j],\n",
      " |                  [ 0.5593+0.j, -0.4443+0.j]], dtype=torch.complex128)\n",
      " |          >>> linear(torch.ones(3, 2, dtype=torch.cdouble))\n",
      " |          tensor([[0.6122+0.j, 0.1150+0.j],\n",
      " |                  [0.6122+0.j, 0.1150+0.j],\n",
      " |                  [0.6122+0.j, 0.1150+0.j]], dtype=torch.complex128)\n",
      " |  \n",
      " |  to_empty(self: ~T, *, device: Union[str, torch.device]) -> ~T\n",
      " |      Moves the parameters and buffers to the specified device without copying storage.\n",
      " |      \n",
      " |      Args:\n",
      " |          device (:class:`torch.device`): The desired device of the parameters\n",
      " |              and buffers in this module.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  train(self: ~T, mode: bool = True) -> ~T\n",
      " |      Sets the module in training mode.\n",
      " |      \n",
      " |      This has any effect only on certain modules. See documentations of\n",
      " |      particular modules for details of their behaviors in training/evaluation\n",
      " |      mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n",
      " |      etc.\n",
      " |      \n",
      " |      Args:\n",
      " |          mode (bool): whether to set training mode (``True``) or evaluation\n",
      " |                       mode (``False``). Default: ``True``.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  type(self: ~T, dst_type: Union[torch.dtype, str]) -> ~T\n",
      " |      Casts all parameters and buffers to :attr:`dst_type`.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Args:\n",
      " |          dst_type (type or string): the desired type\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  xpu(self: ~T, device: Union[int, torch.device, NoneType] = None) -> ~T\n",
      " |      Moves all model parameters and buffers to the XPU.\n",
      " |      \n",
      " |      This also makes associated parameters and buffers different objects. So\n",
      " |      it should be called before constructing optimizer if the module will\n",
      " |      live on XPU while being optimized.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          device (int, optional): if specified, all parameters will be\n",
      " |              copied to that device\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  zero_grad(self, set_to_none: bool = False) -> None\n",
      " |      Sets gradients of all model parameters to zero. See similar function\n",
      " |      under :class:`torch.optim.Optimizer` for more context.\n",
      " |      \n",
      " |      Args:\n",
      " |          set_to_none (bool): instead of setting to zero, set the grads to None.\n",
      " |              See :meth:`torch.optim.Optimizer.zero_grad` for details.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  T_destination = ~T_destination\n",
      " |  \n",
      " |  __annotations__ = {'__call__': typing.Callable[..., typing.Any], '_is_...\n",
      " |  \n",
      " |  dump_patches = False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(nn.GELU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b4f9aa",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "%\\text{GELU}(x) = x * \\Phi(x)\n",
    "\\text{GELU}(x) = 0.5 * x * (1 + \\text{Tanh}(\\sqrt{2 / \\pi} * (x + 0.044715 * x^3)))\n",
    "\\end{equation}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
